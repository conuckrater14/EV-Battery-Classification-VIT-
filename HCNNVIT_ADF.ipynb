{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMrBKrYQJZuz"
   },
   "source": [
    "# Hybrid ViT\u2013CNN Architecture for Lithium-Ion Battery Type Identification on the RecyBat24 Dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZiEJxcjMJhaV"
   },
   "source": [
    "**Importing Required Libraires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IDrXNAu9Jeio"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Image processing libraries\n",
    "from PIL import Image\n",
    "\n",
    "# Data Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Deep Learning libraries\n",
    "import torch\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Other libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6YINAutBI_x"
   },
   "source": [
    "**Mounting google drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGyvZgzjKLm4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "data_dir = '/content/drive/MyDrive/CVA/recybat24'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO5HyGj5cLk-"
   },
   "source": [
    "**Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzaFwF_NJLm6"
   },
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class RecyBatDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_dir = root_dir\n",
    "\n",
    "        with open(os.path.join(root_dir, \"annotations.json\"), \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Image ID \u2192 filename\n",
    "        self.id_to_filename = {\n",
    "            img[\"id\"]: img[\"file_name\"] for img in data[\"images\"]\n",
    "        }\n",
    "\n",
    "        # Image ID \u2192 label ID\n",
    "        self.id_to_label = {\n",
    "            ann[\"image_id\"]: ann[\"category_id\"] for ann in data[\"annotations\"]\n",
    "        }\n",
    "\n",
    "        # Label ID \u2192 class name\n",
    "        self.label_map = {\n",
    "            cat[\"id\"]: cat[\"name\"] for cat in data[\"categories\"]\n",
    "        }\n",
    "\n",
    "        # Convert labels to 0-based indexing\n",
    "        self.label_to_index = {\n",
    "            label_id: idx for idx, label_id in enumerate(self.label_map.keys())\n",
    "        }\n",
    "\n",
    "        self.samples = []\n",
    "        for img_id, file_name in self.id_to_filename.items():\n",
    "            if img_id in self.id_to_label:\n",
    "                self.samples.append((\n",
    "                    os.path.join(self.image_dir, file_name),\n",
    "                    self.label_to_index[self.id_to_label[img_id]]\n",
    "                ))\n",
    "\n",
    "        self.classes = list(self.label_map.values())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      img_path, label = self.samples[idx]\n",
    "      if not os.path.exists(img_path):\n",
    "          print(\"MISSING PATH:\", img_path)\n",
    "      image = Image.open(img_path).convert(\"RGB\")\n",
    "      if self.transform:\n",
    "          image = self.transform(image)\n",
    "      return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Y1C_FJOchso"
   },
   "outputs": [],
   "source": [
    "# Image Denormalizer\n",
    "def denormalize(img_tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    img = img_tensor * std + mean\n",
    "    return img.clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SjK4zAGdpBG"
   },
   "outputs": [],
   "source": [
    "# Funtionc to train the model\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gwb13ZWldthe"
   },
   "outputs": [],
   "source": [
    "# Function to evaluate model\n",
    "def evaluate(model, dataloader, criterion=None):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            if criterion is not None:\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    acc = correct / total\n",
    "    avg_loss = running_loss / len(dataloader) if criterion else None\n",
    "\n",
    "    return avg_loss, acc, all_labels, all_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nn7BGU-PcUtE"
   },
   "source": [
    "**Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4__vTf1mGmu5"
   },
   "outputs": [],
   "source": [
    "train_dataset_temp = RecyBatDataset(\n",
    "    root_dir = os.path.join(data_dir, \"train\"),\n",
    "    transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEDs2KhjLtt6"
   },
   "outputs": [],
   "source": [
    "# Visualizing Class distribution\n",
    "labels = [label for _, label in train_dataset_temp.samples]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(labels, bins=len(train_dataset_temp.classes))\n",
    "plt.xticks(range(len(train_dataset_temp.classes)),\n",
    "           train_dataset_temp.classes, rotation=45)\n",
    "plt.title(\"Class Distribution - RecyBat24\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4Ai4zqaO9jK"
   },
   "source": [
    "**Data Augmentation and Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwjaA3YDP1r_"
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMAGE_SIZE = 224\n",
    "NUM_WORKERS = 4\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgA_TUvHLubd"
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMwO8t8bPfxt"
   },
   "source": [
    "**Dataset & Dataset loaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Jl24ZZsPTvD"
   },
   "outputs": [],
   "source": [
    "train_dataset = RecyBatDataset(\n",
    "    root_dir= os.path.join(data_dir, 'train'),\n",
    "    transform= train_transforms\n",
    ")\n",
    "\n",
    "test_dataset = RecyBatDataset(\n",
    "    root_dir= os.path.join(data_dir, 'val'),\n",
    "    transform=test_transforms\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = NUM_WORKERS\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False,\n",
    "    num_workers = NUM_WORKERS\n",
    ")\n",
    "\n",
    "NUM_CLASSES = len(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJe5Vf25Q-rB"
   },
   "source": [
    "Hybrid CNN-VIT model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bcMOKd0ILuUe"
   },
   "outputs": [],
   "source": [
    "cnn_backbone = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "cnn_feature_dim = cnn_backbone.fc.in_features\n",
    "cnn_backbone.fc = nn.Identity()\n",
    "\n",
    "vit = timm.create_model(\n",
    "    \"vit_base_patch16_224\",\n",
    "    pretrained=True,\n",
    "    num_classes=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lgCTMFSLuSF"
   },
   "outputs": [],
   "source": [
    "class HybridCNNViT(nn.Module):\n",
    "    def __init__(self, cnn, vit, cnn_feature_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.cnn = cnn\n",
    "        self.vit = vit\n",
    "\n",
    "        self.fc = nn.Linear(\n",
    "            cnn_feature_dim + vit.num_features,\n",
    "            num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        cnn_feat = self.cnn(x)\n",
    "        vit_feat = self.vit(x)\n",
    "        combined = torch.cat((cnn_feat, vit_feat), dim=1)\n",
    "        return self.fc(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIpZkg35RXrP"
   },
   "outputs": [],
   "source": [
    "model = HybridCNNViT(\n",
    "    cnn = cnn_backbone,\n",
    "    vit = vit,\n",
    "    cnn_feature_dim = cnn_feature_dim,\n",
    "    num_classes = NUM_CLASSES\n",
    ").to( DEVICE )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zx6p75w7ifZt"
   },
   "source": [
    "**Model training and Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJwPoP2kcuX6"
   },
   "outputs": [],
   "source": [
    "# Defining Hyperparameters\n",
    "EPOCHS = 10\n",
    "LR = 3e-4\n",
    "WD = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4YPEkSOiirz"
   },
   "outputs": [],
   "source": [
    "# Freeze CNN and ViT backbones\n",
    "for param in model.cnn.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.vit.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pt8H5PK3iipw"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.fc.parameters(),\n",
    "    lr = LR,\n",
    "    weight_decay = WD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afoGd8q-iiiu"
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{EPOCHS}] | \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Train Acc: {train_acc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mk5qG7vHiigH"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc, y_true, y_pred = evaluate(\n",
    "    model, test_loader, criterion\n",
    ")\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXkE2PrcjPjk"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        target_names=test_dataset.classes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qObPUjqNLhs-"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=test_dataset.classes,\n",
    "    yticklabels=test_dataset.classes\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDzMRYm1KhXo"
   },
   "source": [
    "**Making Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ko-rzCwWKkuj"
   },
   "outputs": [],
   "source": [
    "LB = test_dataset.classes\n",
    "\n",
    "idx = random.randint(0, len(test_dataset) - 1)\n",
    "image, true_label = test_dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkwew5VJjPgq"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "input_image = image.unsqueeze(0).to(DEVICE)  # shape: [1, 3, 224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5VYKqZvjPea"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_image)\n",
    "    probabilities = torch.softmax(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWPCU01VjPca"
   },
   "outputs": [],
   "source": [
    "predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "confidence_scores = probabilities.squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueTxNDTIjPaX"
   },
   "outputs": [],
   "source": [
    "img_vis = denormalize(image)\n",
    "img_vis = img_vis.permute(1, 2, 0).numpy()\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(img_vis)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\n",
    "    f\"True: {LB[true_label]}\\n\"\n",
    "    f\"Predicted: {LB[predicted_class]}\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RG2QASvajPXj"
   },
   "outputs": [],
   "source": [
    "print(\"Confidence scores:\")\n",
    "for i, score in enumerate(confidence_scores):\n",
    "    print(f\"{labels[i]}: {score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}